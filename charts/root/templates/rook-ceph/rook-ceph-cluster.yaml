apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: rook-ceph-cluster
  finalizers:
    - resources-finalizer.argocd.argoproj.io
spec:
  destination:
    server: https://kubernetes.default.svc
    namespace: rook-ceph
  project: default
  source:
    chart: rook-ceph-cluster
    repoURL: https://charts.rook.io/release
    targetRevision: v1.13.1
    helm:
      values: |
        toolbox:
          enabled: true
        configOverride: |
          [global]
          osd_pool_default_size = 2
          [mon]
          mon_data_avail_warn = 20
        monitoring:
          enabled: true
        ingress:
          dashboard:
            ingressClassName: nginx
            annotations:
              external-dns.alpha.kubernetes.io/hostname: rook-ceph-cluster-dashboard.impl.nl
              external-dns.alpha.kubernetes.io/cloudflare-proxied: "false"
              external-dns.alpha.kubernetes.io/target: ingress.impl.nl
            host:
              name: rook-ceph-cluster-dashboard.impl.nl
            #   # path: "/ceph-dashboard(/|$)(.*)"
            # tls:
            # - hosts:
            #     - dashboard.example.com
            #   secretName: testsecret-tls
            # # Note: Only one of ingress class annotation or the `ingressClassName:` can be used at a time
            # # to set the ingress class
            


            # hosts:
            #   - host: home-assistant.impl.nl
            #     paths:
            #       - path: /



        cephClusterSpec:
          removeOSDsIfOutAndSafeToRemove: true
          mon:
            count: 3
          mgr:
            count: 2
          dashboard:
            enabled: true
            urlPrefix: /
            ssl: false
          storage:
            useAllNodes: false
            useAllDevices: false
            nodes:
              - name: node6
                devices:
                  - name: /dev/disk/by-id/nvme-TS512GMTE400S_I152110465
              - name: node8
                devices:
                  - name: /dev/disk/by-id/nvme-TS512GMTE400S_H908310130 
          crashCollector:
            disable: true
          placement:
            osd:
              tolerations:
                - key: "node.kubernetes.io/unschedulable"
                  operator: "Exists"
                  effect: "NoSchedule"
                - key: node-role.kubernetes.io/control-plane
                  operator: "Exists"
                  effect: "NoSchedule"
            mon:
              tolerations:
                - key: "node.kubernetes.io/unschedulable"
                  operator: "Exists"
                  effect: "NoSchedule"
                - key: node-role.kubernetes.io/control-plane
                  operator: "Exists"
                  effect: "NoSchedule"
            mgr:
              tolerations:
                - key: "node.kubernetes.io/unschedulable"
                  operator: "Exists"
                  effect: "NoSchedule"
                - key: node-role.kubernetes.io/control-plane
                  operator: "Exists"
                  effect: "NoSchedule"
        cephFileSystems: {}
        cephBlockPoolsVolumeSnapshotClass:
          enabled: false
        cephFileSystemVolumeSnapshotClass:
          enabled: false
        cephBlockPools:
          - name: ceph-blockpool
            spec:
              replicated:
                size: 2
            storageClass:
              enabled: true
              name: ceph-block
              isDefault: true
              reclaimPolicy: Retain
              allowVolumeExpansion: true
              parameters:
                imageFormat: "2"
                csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
                csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
                csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
                csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
                csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
                csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph
                csi.storage.k8s.io/fstype: ext4
        cephObjectStores: {}
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - ServerSideApply=true
