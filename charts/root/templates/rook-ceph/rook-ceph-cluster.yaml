apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: rook-ceph-cluster
  finalizers:
    - resources-finalizer.argocd.argoproj.io
spec:
  destination:
    server: https://kubernetes.default.svc
    namespace: rook-ceph
  project: default
  source:
    chart: rook-ceph-cluster
    repoURL: https://charts.rook.io/release
    targetRevision: v1.13.0
    helm:
      values: |
        monitoring:
          enabled: true
        cephClusterSpec:
          mon:
            count: 3
          mgr:
            count: 2
          dashboard:
            enabled: true
            urlPrefix: /
            ssl: false
          removeOSDsIfOutAndSafeToRemove: true
          storage:
            useAllNodes: false
            useAllDevices: false
            nodes:
              - name: node6
                devices:
                  - name: /dev/disk/by-id/nvme-ADATA_SX8200PNP_2L232LQQB4RP
              - name: node8
                devices:
                  - name: /dev/disk/by-id/nvme-ADATA_SX8200PNP_2L2029Q18GKY
          crashCollector:
            disable: true
          placement:
            mgr:
              nodeAffinity:
                requiredDuringSchedulingIgnoredDuringExecution:
                  nodeSelectorTerms:
                    - matchExpressions:
                        - key: node-role.kubernetes.io/control-plane
                          operator: Exists
              tolerations:
                - key: "node.kubernetes.io/unschedulable"
                  operator: "Exists"
                  effect: "NoSchedule"
            mon:
              nodeAffinity:
                requiredDuringSchedulingIgnoredDuringExecution:
                  nodeSelectorTerms:
                    - matchExpressions:
                        - key: node-role.kubernetes.io/control-plane
                          operator: Exists
              tolerations:
                - key: "node.kubernetes.io/unschedulable"
                  operator: "Exists"
                  effect: "NoSchedule"
        cephFileSystems: {}
        cephBlockPoolsVolumeSnapshotClass:
          enabled: false
        cephFileSystemVolumeSnapshotClass:
          enabled: false
        cephBlockPools:
          - name: ceph-blockpool
            spec:
              failureDomain: host
              replicated:
                size: 1
                requireSafeReplicaSize: false
            storageClass:
              enabled: true
              name: ceph-block
              isDefault: false
              reclaimPolicy: Retain
              allowVolumeExpansion: true
              parameters:
                csi.storage.k8s.io/fstype: xfs
              #   imageFormat: "2"
              #   imageFeatures: layering
              #   csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
              #   csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
              #   csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
              #   csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
              #   csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
              #   csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph
              #   csi.storage.k8s.io/fstype: ext4
        cephObjectStores: {}
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - ServerSideApply=true
